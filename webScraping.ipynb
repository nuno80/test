{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BeautifulSoup"
      ],
      "metadata": {
        "id": "tG5ylfOXXPgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3SMTI6KcKrT",
        "outputId": "064a53be-1b73-4911-9d46-4036579a4e3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colored\n",
            "  Downloading colored-2.2.3-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: colored\n",
            "Successfully installed colored-2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests #pip install requests\n",
        "from bs4 import BeautifulSoup #pip install bs4\n",
        "import pygame #pip install  pygame\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from colored import fg, attr\n",
        "from IPython.display import Audio\n",
        "\n",
        "#Opening The Settings.json file\n",
        "with open('settings.json','r') as file:\n",
        "    settings = json.load(file)\n",
        "\n",
        "\n",
        "# Set your budjet\n",
        "my_price = settings['budget']\n",
        "\n",
        "# initializing Currency Symbols to substract it from our string\n",
        "currency_symbols = ['€', '\t£', '$', \"¥\", \"HK$\", \"₹\", \"¥\", \",\" ]\n",
        "\n",
        "# the URL we are going to use\n",
        "URL = settings['url']\n",
        "\n",
        "# Google \"My User Agent\" And Replace It\n",
        "headers = {\"User-Agent\": 'Mozilla/5.0'}\n",
        "\n",
        "#Checking the price\n",
        "def checking_price():\n",
        "    page = requests.get(URL, headers=headers)\n",
        "    soup  = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "    #Finding the elements\n",
        "    product_title = soup.find('span', id='productTitle').getText()\n",
        "    product_price = soup.find('span', class_ = \"a-offscreen\").getText()\n",
        "\n",
        "    # using replace() to remove currency symbols\n",
        "    for i in currency_symbols :\n",
        "        product_price = product_price.replace(i, '')\n",
        "\n",
        "    #Converting the string to integer\n",
        "    product_price = int(float(product_price))\n",
        "\n",
        "    ProductTitleStrip = product_title.strip()\n",
        "    print(f\"{fg('green_1')}The Product Name is:{attr('reset')}{fg('dark_slate_gray_2')} {ProductTitleStrip}{attr('reset')}\")\n",
        "    print(f\"{fg('green_1')}The Price is:{attr('reset')}{fg('orange_red_1')} {product_price}{attr('reset')}\")\n",
        "\n",
        "\n",
        "\n",
        "    # checking the price\n",
        "    if(product_price<my_price):\n",
        "        # Riproduci il file ding.wav\n",
        "        Audio(\"ding.wav\", autoplay=True)\n",
        "        print(f\"{fg('medium_orchid_1b')}You Can Buy This Now!{attr('reset')}\")\n",
        "        time.sleep(3) # audio will be played first then exit the program. This time for audio playing.\n",
        "        exit()\n",
        "    else:\n",
        "        print(f\"{fg('red_1')}The Price Is Too High!{attr('reset')}\")\n",
        "\n",
        "while True:\n",
        "    checking_price()\n",
        "    time.sleep(settings['remind-time']) #It is set to run the program once in an hour! You can change by changing the value in seconds!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "9p7VrXksXQCx",
        "outputId": "4b39328f-480b-4496-daa3-7e68ab15c9cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1f393b1a2a84>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mchecking_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'remind-time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#It is set to run the program once in an hour! You can change by changing the value in seconds!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1f393b1a2a84>\u001b[0m in \u001b[0;36mchecking_price\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#Finding the elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mproduct_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'productTitle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mproduct_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a-offscreen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests #pip install requests\n",
        "from bs4 import BeautifulSoup #pip install bs4\n",
        "#import pygame #pip install  pygame\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from colored import fg, attr\n",
        "from IPython.display import Audio\n",
        "\n",
        "#Opening The Settings.json file\n",
        "with open('settings.json','r') as file:\n",
        "    settings = json.load(file)\n",
        "\n",
        "\n",
        "# Set your budjet\n",
        "my_price = settings['budget']\n",
        "\n",
        "# the URL we are going to use\n",
        "URL = settings['url']\n",
        "\n",
        "print(URL)\n",
        "\n",
        "# Google \"My User Agent\" And Replace It\n",
        "headers = {\"User-Agent\": 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "page = requests.get(URL, headers=headers)\n",
        "soup  = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "\n",
        "# Verifica se l'elemento HTML con l'id 'productTitle' è presente nella pagina web\n",
        "if soup.find('span', id='productTitle') is not None:\n",
        "    product_title = soup.find('span', id='productTitle').getText()\n",
        "    #product_title = soup.find('span', class_ ='a-size-large product-title-word-break').getText()\n",
        "\n",
        "    ProductTitleStrip = product_title.strip()\n",
        "    print(ProductTitleStrip)\n",
        "\n",
        "else:\n",
        "    print(\"Error: The element with the id 'productTitle' was not found in the web page.\")\n",
        "\n",
        "product_price_iniziale = soup.find('span', class_ = \"a-price-whole\").getText()\n",
        "# Rimuove la virgola alla fine della stringa\n",
        "product_price = int(product_price_iniziale.rstrip(\",\"))\n",
        "print(product_price)\n",
        "type(product_price)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clsFx_3oiCpp",
        "outputId": "ce3fb1e3-0642-4b83-c1d2-d9b8145fde53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.amazon.it/SWFT210-Radeon-6650-Core-Gaming/dp/B09ZLRDMXX/ref=sr_1_2?__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=VKSPUE55WEXW&keywords=amd+6650&qid=1698935658&sprefix=amd+6650%2Caps%2C221&sr=8-2\n",
            "SWFT210 RADEON RX 6650 XT CORE Gaming\n",
            "259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_price_iniziale = soup.find('span', class_ = \"a-price-whole\").getText()\n",
        "# Rimuove la virgola alla fine della stringa\n",
        "product_price = int(product_price_iniziale.rstrip(\",\"))\n",
        "\n",
        "print(product_price)\n",
        "type(product_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "GkjlythF82H-",
        "outputId": "418ba2b0-a501-441c-bff1-a575b66235cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-60ed1f7e77bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproduct_price_iniziale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a-price-whole\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Rimuove la virgola alla fine della stringa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproduct_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_price_iniziale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Python Script to extract product information\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Function to extract Product Title\n",
        "def get_title(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\t# Outer Tag Object\n",
        "\t\ttitle = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
        "\n",
        "\t\t# Inner NavigableString Object\n",
        "\t\ttitle_value = title.string\n",
        "\n",
        "\t\t# Title as a string value\n",
        "\t\ttitle_string = title_value.strip()\n",
        "\n",
        "\t\t# # Printing types of values for efficient understanding\n",
        "\t\t# print(type(title))\n",
        "\t\t# print(type(title_value))\n",
        "\t\t# print(type(title_string))\n",
        "\t\t# print()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\ttitle_string = \"\"\n",
        "\n",
        "\treturn title_string\n",
        "\n",
        "# Function to extract Product Price\n",
        "def get_price(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\tprice = soup.find(\"span\", attrs={'id':'corePrice_feature_ div'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\ttry:\n",
        "\t\t\tprice = soup.find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
        "\t\texcept:\n",
        "\t\t\tprice = \"\"\n",
        "\n",
        "\treturn price\n",
        "\n",
        "# Function to extract Product Rating\n",
        "def get_rating(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\trating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\trating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
        "\t\texcept:\n",
        "\t\t\trating = \"\"\n",
        "\n",
        "\treturn rating\n",
        "\n",
        "# Function to extract Number of User Reviews\n",
        "def get_review_count(soup):\n",
        "\ttry:\n",
        "\t\treview_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\treview_count = \"\"\n",
        "\n",
        "\treturn review_count\n",
        "\n",
        "# Function to extract Availability Status\n",
        "def get_availability(soup):\n",
        "\ttry:\n",
        "\t\tavailable = soup.find(\"div\", attrs={'id':'availability'})\n",
        "\t\tavailable = available.find(\"span\").string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\tavailable = \"\"\n",
        "\n",
        "\treturn available\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\t# Headers for request\n",
        "\tHEADERS = ({'User-Agent':\n",
        "\t            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.64',\n",
        "\t            'Accept-Language': 'en-US, en;q=0.5'})\n",
        "\n",
        "\t# The webpage URL\n",
        "\tURL = \"https://www.amazon.it/MSI-Radeon-6650-MECH-GDDR6/dp/B09YHXT12P/ref=sr_1_1?__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=XZET7XGSNFUE&keywords=amd+6650&qid=1699287112&sr=8-1\"\n",
        "\n",
        "\t# HTTP Request\n",
        "\twebpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "\t# Soup Object containing all data\n",
        "\tsoup = BeautifulSoup(webpage.content, \"lxml\")\n",
        "\n",
        "\t# Function calls to display all necessary product information\n",
        "\tprint(\"Product Title =\", get_title(soup))\n",
        "\tprint(\"Product Price =\", get_price(soup))\n",
        "\tprint(\"Product Rating =\", get_rating(soup))\n",
        "\tprint(\"Number of Product Reviews =\", get_review_count(soup))\n",
        "\tprint(\"Availability =\", get_availability(soup))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMdbuADU68or",
        "outputId": "da7747a1-1c2d-4128-a701-2fb51665c621"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Title = MSI Radeon RX 6650 XT MECH 2X 8G OC Scheda Video - AMD RX 6650 XT, GPU 2447/2669 MHz, 8000 MB di Memoria DDR6, Velocità di Memoria 17500 MHz, Bus di Memoria 128bit\n",
            "Product Price = 313,24€\n",
            "Product Rating = 4,6 su 5 stelle\n",
            "Number of Product Reviews = 2.039 voti\n",
            "Availability = Disponibilità: solo 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Python Script to extract product details across multiple webpages\n",
        "#codice funzionante su amazon.us\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Function to extract Product Title\n",
        "def get_title(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\t# Outer Tag Object\n",
        "\t\ttitle = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
        "\n",
        "\t\t# Inner NavigatableString Object\n",
        "\t\ttitle_value = title.string\n",
        "\n",
        "\t\t# Title as a string value\n",
        "\t\ttitle_string = title_value.strip()\n",
        "\n",
        "\t\t# # Printing types of values for efficient understanding\n",
        "\t\t# print(type(title))\n",
        "\t\t# print(type(title_value))\n",
        "\t\t# print(type(title_string))\n",
        "\t\t# print()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\ttitle_string = \"\"\n",
        "\n",
        "\treturn title_string\n",
        "\n",
        "# Function to extract Product Price\n",
        "def get_price(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\tprice = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\t# If there is some deal price\n",
        "\t\t\tprice = soup.find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
        "\n",
        "\t\texcept:\n",
        "\t\t\tprice = \"\"\n",
        "\n",
        "\treturn price\n",
        "\n",
        "# Function to extract Product Rating\n",
        "def get_rating(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\trating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\trating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
        "\t\texcept:\n",
        "\t\t\trating = \"\"\n",
        "\n",
        "\treturn rating\n",
        "\n",
        "# Function to extract Number of User Reviews\n",
        "def get_review_count(soup):\n",
        "\ttry:\n",
        "\t\treview_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\treview_count = \"\"\n",
        "\n",
        "\treturn review_count\n",
        "\n",
        "# Function to extract Availability Status\n",
        "def get_availability(soup):\n",
        "\ttry:\n",
        "\t\tavailable = soup.find(\"div\", attrs={'id':'availability'})\n",
        "\t\tavailable = available.find(\"span\").string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\tavailable = \"Not Available\"\n",
        "\n",
        "\treturn available\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\t# Headers for request\n",
        "\tHEADERS = ({'User-Agent':\n",
        "\t            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
        "\t            'Accept-Language': 'en-US'})\n",
        "\n",
        "\t# The webpage URL\n",
        "\tURL = \"https://www.amazon.com/s?k=playstation+4&ref=nb_sb_noss_2\"\n",
        "\n",
        "\t# HTTP Request\n",
        "\twebpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "\t# Soup Object containing all data\n",
        "\tsoup = BeautifulSoup(webpage.content, \"lxml\")\n",
        "\n",
        "\t# Fetch links as List of Tag Objects\n",
        "\tlinks = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
        "\n",
        "\t# Store the links\n",
        "\tlinks_list = []\n",
        "\n",
        "\t# Loop for extracting links from Tag Objects\n",
        "\tfor link in links:\n",
        "\t\tlinks_list.append(link.get('href'))\n",
        "\n",
        "\n",
        "\t# Loop for extracting product details from each link\n",
        "\tfor link in links_list:\n",
        "\n",
        "\t\tnew_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
        "\n",
        "\t\tnew_soup = BeautifulSoup(new_webpage.content, \"lxml\")\n",
        "\n",
        "\t\t# Function calls to display all necessary product information\n",
        "\t\tprint(\"Product Title =\", get_title(new_soup))\n",
        "\t\tprint(\"Product Price =\", get_price(new_soup))\n",
        "\t\tprint(\"Product Rating =\", get_rating(new_soup))\n",
        "\t\tprint(\"Number of Product Reviews =\", get_review_count(new_soup))\n",
        "\t\tprint(\"Availability =\", get_availability(new_soup))\n",
        "\t\tprint()\n",
        "\t\tprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "0Q-r7f4NQxx_",
        "outputId": "7d60cdf9-3cf5-40fb-a0b0-18fce848b19b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Title = \n",
            "Product Price = \n",
            "Product Rating = \n",
            "Number of Product Reviews = \n",
            "Availability = Not Available\n",
            "\n",
            "\n",
            "Product Title = Sony Playstation PS4 1TB Black Console\n",
            "Product Price = $339.00\n",
            "Product Rating = 4.6 out of 5 stars\n",
            "Number of Product Reviews = 1,253 ratings\n",
            "Availability = In Stock\n",
            "\n",
            "\n",
            "Product Title = Sony PlayStation 4 Pro w/ Accessories, 1TB HDD, CUH-7215B - Jet Black (Renewed)\n",
            "Product Price = $279.97\n",
            "Product Rating = 4.1 out of 5 stars\n",
            "Number of Product Reviews = 724 ratings\n",
            "Availability = Only 2 left in stock - order soon.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-31a2a1da26d5>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mnew_webpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.amazon.com\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mnew_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_webpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Python Script to extract product details across multiple webpages\n",
        "#codice per amazon.IT\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Function to extract Product Title\n",
        "def get_title(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\t# Outer Tag Object\n",
        "\t\ttitle = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
        "\n",
        "\t\t# Inner NavigatableString Object\n",
        "\t\ttitle_value = title.string\n",
        "\n",
        "\t\t# Title as a string value\n",
        "\t\ttitle_string = title_value.strip()\n",
        "\n",
        "\t\t# # Printing types of values for efficient understanding\n",
        "\t\t# print(type(title))\n",
        "\t\t# print(type(title_value))\n",
        "\t\t# print(type(title_string))\n",
        "\t\t# print()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\ttitle_string = \"\"\n",
        "\n",
        "\treturn title_string\n",
        "\n",
        "# Function to extract Product Price\n",
        "def get_price(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\tprice = soup.find(\"span\", attrs={'id':'corePrice_feature_ div'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\ttry:\n",
        "\t\t\tprice = soup.find(\"span\", attrs={'class':'a-offscreen'}).string.strip()\n",
        "\t\texcept:\n",
        "\t\t\tprice = \"\"\n",
        "\n",
        "\treturn price\n",
        "\n",
        "# Function to extract Product Rating\n",
        "def get_rating(soup):\n",
        "\n",
        "\ttry:\n",
        "\t\trating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\trating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
        "\t\texcept:\n",
        "\t\t\trating = \"\"\n",
        "\n",
        "\treturn rating\n",
        "\n",
        "# Function to extract Number of User Reviews\n",
        "def get_review_count(soup):\n",
        "\ttry:\n",
        "\t\treview_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\treview_count = \"\"\n",
        "\n",
        "\treturn review_count\n",
        "\n",
        "# Function to extract Availability Status\n",
        "def get_availability(soup):\n",
        "\ttry:\n",
        "\t\tavailable = soup.find(\"div\", attrs={'id':'availability'})\n",
        "\t\tavailable = available.find(\"span\").string.strip()\n",
        "\n",
        "\texcept AttributeError:\n",
        "\t\tavailable = \"Not Available\"\n",
        "\n",
        "\treturn available\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\t# Headers for request\n",
        "\tHEADERS = ({'User-Agent':'Mozilla/5.0'})\n",
        "\n",
        "\t# The webpage URL\n",
        "\tURL = \"https://www.amazon.it/s?k=amd+6650&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=XZET7XGSNFUE\"\n",
        "\n",
        "\t# HTTP Request\n",
        "\twebpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "\t# Soup Object containing all data\n",
        "\tsoup = BeautifulSoup(webpage.content, \"lxml\")\n",
        "\n",
        "\t# Fetch links as List of Tag Objects\n",
        "\tlinks = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
        "\n",
        "\t# Store the links\n",
        "\tlinks_list = []\n",
        "\n",
        "\t# Loop for extracting links from Tag Objects\n",
        "\tfor link in links:\n",
        "\t\tlinks_list.append(link.get('href'))\n",
        "\n",
        "\t# Loop for extracting product details from each link\n",
        "\tfor link in links_list:\n",
        "\n",
        "\t\tnew_webpage = requests.get(\"https://www.amazon.it\" + link, headers=HEADERS)\n",
        "\n",
        "\t\tnew_soup = BeautifulSoup(new_webpage.content, \"lxml\")\n",
        "\n",
        "\t\t# Function calls to display all necessary product information\n",
        "\t\tprint(\"Product Title =\", get_title(new_soup))\n",
        "\t\tprint(\"Product Price =\", get_price(new_soup))\n",
        "\t\tprint(\"Product Rating =\", get_rating(new_soup))\n",
        "\t\tprint(\"Number of Product Reviews =\", get_review_count(new_soup))\n",
        "\t\tprint(\"Availability =\", get_availability(new_soup))\n",
        "\t\tprint()\n",
        "\t\tprint()"
      ],
      "metadata": {
        "id": "HmONtpTucC9V"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTTPX e SELETOLAX"
      ],
      "metadata": {
        "id": "D-jUF66Tvlel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install HTTPX\n",
        "!pip install SELECTOLAX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qglGLQCDonUJ",
        "outputId": "e02dd9e9-6793-453d-b005-b5f2429116dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting HTTPX\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/75.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from HTTPX) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from HTTPX) (2023.7.22)\n",
            "Collecting httpcore (from HTTPX)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from HTTPX) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from HTTPX) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->HTTPX) (1.1.3)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->HTTPX)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, HTTPX\n",
            "Successfully installed HTTPX-0.25.1 h11-0.14.0 httpcore-1.0.1\n",
            "Collecting SELECTOLAX\n",
            "  Downloading selectolax-0.3.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SELECTOLAX\n",
            "Successfully installed SELECTOLAX-0.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#web-scraping con HTTPX e SELECTOLAX\n",
        "\n",
        "import httpx\n",
        "from selectolax.parser import HTMLParser\n",
        "import pandas\n",
        "\n",
        "#settiamo il sito da cui estrarre i dati\n",
        "url = \"https://www.rei.com/c/camping-and-hiking/f/scd-deals\"\n",
        "\n",
        "#ogni PC ha il suo user-agent, per trovarlo cerca sul web \"my user-agent\"\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.64'}\n",
        "\n",
        "#carichiamo la pagina web con HTTPX, più efficiente e moderno di beautifulsoup e analizziamo (parse) la pagina html con selectolax in modo da trasformarla in testo\n",
        "resp = httpx.get(url, headers=headers)\n",
        "\n",
        "#è fondamentale fare un print di resp. Se non ho un codice 200 è inutile continuare, non troverò mai nulla perchè non ho accesso alla agina web\n",
        "print(resp)\n",
        "html = HTMLParser(resp.text) #html rappresenta un oggetto HTMLParser che a sua volta rappresenta la pagina HTML da cui estrarre i dati\n",
        "\n",
        "#creiamo una funzione per estrarre i dati desiderati prevedendo che in caso di errore o dato non trovato la funzione ritorni \"None\" dove:\n",
        "#sel rappresenta il selettore CSS che verrà utilizzato per trovare l'elemento HTML da cui estrarre il testo.\n",
        "def extract_text(html, sel):\n",
        "    try:\n",
        "      return html.css_first(sel).text()\n",
        "    except AttributeError:\n",
        "      return None\n",
        "\n",
        "#nel sito di riferimento tutti i prodotti sono dettagliati all'interno di uno specifico box definito come: <li class =\"Xpx0MUGhB7jSm5UvK2EY\">. Pertanto:\n",
        "products = html.css(\"li.VcGDfKKy_dvNbxUqm29K\")\n",
        "\n",
        "for product in products:\n",
        "  items = {\n",
        "      \"name\": extract_text(product, \".Xpx0MUGhB7jSm5UvK2EY\"),#per estrarre il nome posso far riferimento alla classe. Il punto davanti al nome della classe indica che il selettore CSS deve cercare un elemento HTML con la classe specificata\n",
        "      \"name1\": extract_text(product, \"span[data-ui=product-title]\"),#per estrarre il nome posso far riferimento anche al nome dello span che va però inserito tra []\n",
        "      \"price\": extract_text(product, \"span[data-ui=sale-price]\"),\n",
        "  }\n",
        "  df = pd.DataFrame(items)\n",
        "\n",
        "  # Rimuovi la colonna \"name1\", poiché non è necessaria\n",
        "  df = df.drop(\"name1\", axis=1)\n",
        "\n",
        "  # Rinomina la colonna \"name\" in \"product\"\n",
        "  df.rename(columns={\"name\": \"product\"}, inplace=True)\n",
        "\n",
        "  print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "e0CzdR2qlpH5",
        "outputId": "d9df6ece-707a-42bc-d059-041100df475a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200 OK]>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b10e209e3709>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"price\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"span[data-ui=sale-price]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   }\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Rimuovi la colonna \"name1\", poiché non è necessaria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "from selectolax.parser import HTMLParser\n",
        "import pandas as pd\n",
        "\n",
        "#settiamo il sito da cui estrarre i dati\n",
        "url = \"https://www.amazon.it/s?k=nvidia+4070\"\n",
        "\n",
        "#url = \"https://www.example.com/products\" # da 404\n",
        "\n",
        "#ogni PC ha il suo user-agent, per trovarlo cerca sul web \"my user-agent\"\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "#carichiamo la pagina web con HTTPX, più efficiente e moderno di beautifulsoup e analizziamo (parse) la pagina html con selectolax in modo da trasformarla in testo\n",
        "resp = httpx.get(url, headers=headers)\n",
        "print(resp)#importante perchè se non ho 200 non posso continuare\n",
        "\n",
        "#creiamo una funzione per estrarre i dati desiderati prevedendo che in caso di errore o dato non trovato la funzione ritorni \"None\" dove:\n",
        "#sel rappresenta il selettore CSS che verrà utilizzato per trovare l'elemento HTML da cui estrarre il testo.\n",
        "def extract_text(html, sel):\n",
        "    try:\n",
        "      return html.css_first(sel).text()\n",
        "    except AttributeError:\n",
        "      return None\n",
        "\n",
        "#se la richiesta è andata a buon fine\n",
        "if resp.status_code == 200:\n",
        "\n",
        "    #analizziamo (parse) la pagina html con selectolax in modo da trasformarla in testo\n",
        "    html = HTMLParser(resp.text)\n",
        "\n",
        "    #nel sito di riferimento tutti i prodotti sono dettagliati all'interno di uno specifico box definito come: class =\"sg-col-inner\">. Pertanto:\n",
        "    products = html.css(\".sg-col-inner\")\n",
        "    print(len(products))\n",
        "\n",
        "    #creiamo un DataFrame per memorizzare i dati\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    #iteriamo i prodotti e salviamoli in un dizionario python\n",
        "    for product in products:\n",
        "      items = {\n",
        "      \"name\": extract_text(product, \"h2\"),#per estrarre il nome posso far riferimento alla classe. Il punto davanti al nome della classe indica che il selettore CSS deve cercare un elemento HTML con la classe specificata\n",
        "      \"price\": extract_text(product, \".a-price-whole\"),\n",
        "      \"stars\": extract_text(product, \".a-icon-alt\"),\n",
        "      }\n",
        "      print(items)\n",
        "else:\n",
        "    print(f\"Errore: codice di stato {resp.status_code}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "w2zwAB5xbFXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoscraper"
      ],
      "metadata": {
        "id": "tSxFv_uxxq0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoscraper"
      ],
      "metadata": {
        "id": "lksL-EhmtwId",
        "outputId": "fdd11707-c61f-46e2-d1ff-c1c55cdcebe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autoscraper\n",
            "  Downloading autoscraper-1.1.14-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autoscraper) (2.31.0)\n",
            "Collecting bs4 (from autoscraper)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from autoscraper) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->autoscraper) (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autoscraper) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->autoscraper) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=a045e73f13b001a7ee409ba7f9041728f4889e3473cd414dda75a699dfe71b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4, autoscraper\n",
            "Successfully installed autoscraper-1.1.14 bs4-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autoscraper import AutoScraper\n",
        "\n",
        "url = 'https://finance.yahoo.com/quote/AAPL/'\n",
        "\n",
        "wanted_list = [\"Apple Inc. (AAPL)\"]\n",
        "\n",
        "scraper = AutoScraper()\n",
        "\n",
        "# Here we can also pass html content via the html parameter instead of the url (html=html_content)\n",
        "result = scraper.build(url, wanted_list)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "eg4IoxA5t2WQ",
        "outputId": "06eaf011-b6dc-4426-860c-575cb0c0d6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple Inc. (AAPL)', '183.07+0.18 (+0.10%)As of  10:49AM EST. Market open.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autoscraper import AutoScraper\n",
        "\n",
        "url = 'https://www.amazon.it/s?k=nvidia+4070'\n",
        "\n",
        "wanted_list = [\"1.029,00€\"]\n",
        "\n",
        "scraper = AutoScraper()\n",
        "\n",
        "# Here we can also pass html content via the html parameter instead of the url (html=html_content)\n",
        "result = scraper.build(url, wanted_list)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "GQXuOCCJxjMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Un benvenuto a Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}